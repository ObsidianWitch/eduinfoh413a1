\section{Exercise 1.1}

\subsection{Implementation}
The program's architecture will be discussed in this section. The main entry
point for the first exercise's program is the \emph{IterativeImprovement/main\_ii.cpp}
file.\\

Command line arguments are parsed using an instance of the \emph{GlobalArgsII}
struct which checks that all arguments are correctly filled. The arguments are
stored in this struct attributes. The arguments which must be specified are
the 3 types of rules (initialisation, pivoting rule and neighbourhood) and the
instance file.\\

\begin{lstlisting}
> ./lop
Usage:./lop -i <initialization_rule (cw|random)>
	-p <pivoting_rule (first|best)>
	-n <neighbourhood (transpose|exchange|insert)>
	-f <instance_file>

> ./lop -i cw -p first -n exchange -f ../instances/N-be75eec_150
...
\end{lstlisting}
\

The arguments are then given to the \emph{RulesFactory} in order to get the
desired instances of an initialization, a neighbourhood and a pivoting rule.
Each rule inherits respectively from the \emph{Initialization},
\emph{Neighbourhood} and \emph{Improvement} abstract classes. By doing so, we
can easily extend the program (adding rules).\\

The body of the algorithm which uses the 3 rules previously defined is described
in the \emph{IterativeImprovement} class.\\

\begin{lstlisting}
void IterativeImprovement::run() {
    bool localOptimum = false;
    Permutation p1 = initialization_.generateInitialization();
    instance_.evaluate(p1);
    
    while (!localOptimum) {
        Permutation p2 = improvement_.improve(p1, neighbourhood_);
        
        localOptimum = (p1 == p2);
        p1 = p2;
    }
}
\end{lstlisting}
\

The two main classs used in this program are the \emph{Instance} and
\emph{Permutation} classes. The first one loads a matrix from an instance file
and stores it in a 2D vector. The second one contains a 1D vector representing
the permutation concept described in the subject's slides.\\

The \textbf{Instance::evaluate()} method is used to compute an instance's score
with the help of a permutation. The following formula corresponds to the sum
computed by this method:\\
$\sum_{i=0}^{n-1} \sum_{j=i+1}^{n-1} m(\pi[i], \pi[j])$, with $\pi$ a
permutation.\\

We do not need to recompute the sum from each cells between two permutations,
there are cells which can be reused: $newScore = oldScore + delta$
with \emph{delta} containing the contribution from the cells in the new
permutation which were modified minus the score from the cells in the old
permutation which were modified. The delta is different for each neighbourhood
and computed in the \emph{dela()} method defined in the three neighbourhoods
(i.e. transpose, exchange, insert).\\

The delta for the insert neighbourhood was found by reading a paper from
\emph{Tommaso Schiavinotto} \& \emph{Thomas St√ºtzle} \cite{cite:lopPaper}.
The other ones were deduced from it.\\

\begin{lstlisting}
long int InsertNeighbourhood::delta(const Matrix& matrix,
    const Permutation& oldP) const
{
    unsigned first = p_.first;
    unsigned second = p_.second;
    unsigned oldPfirst = oldP[first];
    
    long int delta = 0;
    if (first < second) {
        for (unsigned k = first + 1 ; k <= second ; k++) {
            delta += matrix[oldP[k]][oldPfirst] - matrix[oldPfirst][oldP[k]];
        }
    }
    else if (first > second) {
        for (unsigned k = second ; k <= first - 1 ; k++) {
            delta += matrix[oldPfirst][oldP[k]] - matrix[oldP[k]][oldPfirst];
        }
    }
    
    return delta;
}
\end{lstlisting}
\

The delta for the transpose neighbourhood ($N_t$) can reuse the one from the
insert neighbourhood ($N_i$) and be simplified. First of all, $first < second$
were $first$ and $second$ which are the axis which will be modified to obtain
the new permutation. Then, $first + 1 == second$, so the loop can be removed
since it will have only one iteration.\\

\begin{lstlisting}

long int TransposeNeighbourhood::delta(const Matrix& matrix,
    const Permutation& oldP) const
{
    unsigned oldPfirst = oldP[p_.first];
    unsigned oldPsecond = oldP[p_.second];

    long int delta = matrix[oldPsecond][oldPfirst] - matrix[oldPfirst][oldPsecond];

    return delta;
}
\end{lstlisting}
\

As for the exchange neighbourhood ($N_e$), $N_t \subset N_e$, so the delta can
be built on top of the transpose neighbourhood's one.\\

\begin{lstlisting}
long int ExchangeNeighbourhood::delta(const Matrix& matrix,
    const Permutation& oldP) const
{
    unsigned first = p_.first;
    unsigned second = p_.second;
    unsigned oldPfirst = oldP[first];
    unsigned oldPsecond = oldP[second];

    long int delta = matrix[oldPsecond][oldPfirst] - matrix[oldPfirst][oldPsecond];
    for (unsigned k = first + 1 ; k < second ; k++) {
        delta += matrix[oldPsecond][oldP[k]] - matrix[oldPfirst][oldP[k]];
        delta += matrix[oldP[k]][oldPfirst] - matrix[oldP[k]][oldPsecond];
    }

    return delta;
}
\end{lstlisting}
\

Finally these delta can be used in the \emph{Instance::evaluate()} method to
compute the score for a new permutation from the Instance, the old permutation
and the pair of axis which will be modified. This method is in turn used in
the \emph{First/BestImprovement} classes in order to evaluate if a new
permutation should be generated based on its score.\\

\begin{framewarning}
	As can be seen previously, OOP mechanisms were used throughout the program
	(e.g. abstraction, inclusion polymorphism). By doing so, new rules can be
	added easily. But these mechanisms introduce indirections which may slow
	down the computation time compared to a program written without OOP.
\end{framewarning}

\newpage

\subsection{Results}

At first, problems were encountered regarding the computation time of algorithms
with the exchange and insert neighbourhoods. These neighbourhoods
are large and as such the scores took a long time to compute. By using the
optimizations described in the previous section, computation times were
drastically improved.\\

One method to reduce the computation time further would have been to proceed to
neighbourhood pruning in order to remove some neighbours which would not have
been likely to improve the score.\\

\noindent As for the scripts, a brief description can be seen below. The
\emph{generate\_experiments.sh} script was executed on 2 machines with 8 cores
each (details in the introduction) to take care of the 14 combinations of
programs.

\begin{lstlisting}[language=bash]
# Execute all the experiments sequentially (will take a few hours)
> ./generate_experiments.lua

OR

# Execute one type of experiment on all instances
> ./generate_experiments_one.lua lop <random|cw> <first|best>
                                     <transpose|exchange|insert>
> ./generate_experiments_one.lua vnd <tei|tie>

OR

# Execute all the experiments in parallel.
# Comment lines inside the script in order to execute k experiments where k is
# the number of threads your processor can run.
> ./generate_experiments.sh
\end{lstlisting}
\

The format from the files generated by these scripts can be seen below. All the
experiments results were saved in the \textbf{experiments directory}.

\begin{lstlisting}
instance_name score best_known_score relative_percentage_deviation computation_time

N-be75eec_150 3267050 3482828 6.1954825216749 1.22026
N-be75eec_250 8594018 8893533 3.3677842090427 12.5494
N-be75np_150 6843802 7174325 4.6070257480669 1.33389
N-be75np_250 17032098 17814072 4.3896420762193 13.7589
...
\end{lstlisting}
\

The \emph{script/compute\_averages.lua} script takes all the data from the
previously generated experiments files and computes averages from it.\\

\begin{lstlisting}
experiment_name average_delta time_sum time_average

ii_cw_best_exchange 4.4042215638761 553.60109 7.0974498717949
ii_cw_best_insert 2.7739515142054 622.65918 7.98281
ii_cw_best_transpose 17.549047663734 1.92926601 0.024734179615385
ii_cw_first_exchange 3.4509963608726 2954.77757 37.881763717949
ii_cw_first_insert 2.6584281251769 1956.65391 25.085306538462
ii_cw_first_transpose 17.561188605784 1.93007776 0.024744586666667
ii_random_best_exchange 3.5884341872336 636.49971 8.1602526923077
ii_random_best_insert 2.2912062196199 699.15021 8.9634642307692
ii_random_best_transpose 34.183520453804 0.159127704 0.0020400987692308
ii_random_first_exchange 2.8348219580937 4029.14031 51.655645
ii_random_first_insert 2.0220145177762 3475.42275 44.556701923077
ii_random_first_transpose 34.299452518199 0.107179425 0.0013740951923077
vnd_tei 2.6595640233508 1970.80062 25.266674615385
vnd_tie 2.6487053958858 1352.99196 17.346050769231
\end{lstlisting}

\newpage

\subsection{Tests}
We previously computed the relative percentage deviation for each instance, in
each experiment. We would like to know if there are statistically significant
differences between the solution quality generated by the different algorithms.
In order to do that, we use statistical hypothesis tests, the student's t-test
and the Wilcoxon signed-rank test. This tests test a statement called the
null hypothesis which in this case is: "the median of the differences between
results in two experiments is zero". We fix the significance level $\alpha$ to
0.05. If the computed p-value is below $\alpha$, the null hypothesis is rejected
which in this case means that there is a significant difference between
experiments.\\

An R script (\emph{scripts/statistical\_hypothesis\_tests.R}) was written in order
to apply these tests to all possible pairs of experiments. The output was saved
in the \emph{experiments/stats\_tests} directory (reminder: these
results do not have much significance, because the experiments were run on
the transpose neighbourhoods + 2 other neighbourhoods which were intended by the
assignment subject).\\

\begin{lstlisting}[language=R]
#!/usr/bin/Rscript

# arg[1] should be "ii" or "vnd"
args <- commandArgs(trailingOnly = TRUE)

if (args[1] != "ii" && args[1] != "vnd") {
    stop("Usage: ./script <ii|vnd>")
}

experiments_dir <- "../experiments/"
experiments <- list.files(experiments_dir, args[1])
deltas <- array(0, c(length(experiments), 78))

for (i in 1:length(experiments)) {
    experiment_path <- paste(experiments_dir, experiments[i], sep="")
    deltas[i,] <- read.table(experiment_path)$V4
}

results <- array(0, c(length(experiments), length(experiments), 2))
for (i in 1 : (length(experiments)-1)) {
    for (j in (i+1) : length(experiments)) {
        # Student's t test
        results[i,j,1] <- t.test(deltas[i,], deltas[j,], paired=T)$p.value
        
        # Wilcoxon signed-rank test
        results[i,j,2] <- wilcox.test(deltas[i,], deltas[j,], paired=T)$p.value
    }
}

out.dir = "../out/stats_tests"
out.path = paste(out.dir, args[1], sep="/")
dir.create(out.dir, showWarnings=FALSE)
write.table(results[,,1], paste(out.path, "t", sep="_"))
write.table(results[,,2], paste(out.path, "wilcoxon", sep="_"))
\end{lstlisting}

\newpage
