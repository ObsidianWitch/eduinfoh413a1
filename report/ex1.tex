\section{Exercise 1.1}

\subsection{Implementation}
The program's architecture will be discussed in this section. The main entry
point for the first exercise's program is the \emph{IterativeImprovement/main\_ii.cpp}
file.\\

Command line arguments are parsed using an instance of the \emph{GlobalArgsII}
struct which checks that all arguments are correctly filled. The arguments are
stored in this struct attributes. The arguments which must be specified are
the 3 types of rules (initialisation, pivoting rule and neighbourhood) and the
instance file.\\

\begin{lstlisting}
> ./lop
Usage:./lop -i <initialization_rule (cw|random)>
	-p <pivoting_rule (first|best)>
	-n <neighbourhood (transpose|exchange|insert)>
	-f <instance_file>

> ./lop -i cw -p first -n exchange -f ../instances/N-be75eec_150
...
\end{lstlisting}
\

The arguments are then given to the \emph{RulesFactory} in order to get the
desired instances of an initialization, a neighbourhood and a pivoting rule.
Each rule inherits respectively from the \emph{Initialization},
\emph{Neighbourhood} and \emph{Improvement} abstract classes. By doing so, we
can easily extend the program (adding rules).\\

The body of the algorithm which uses the 3 rules previously defined is described
in the \emph{IterativeImprovement} class.\\

\begin{lstlisting}
void IterativeImprovement::run() {
    Permutation p(instance_.size());

    bool localOptimum = false;
    instance_.evaluate(p1);
    
    while (!localOptimum) {
        Permutation p2 = improvement_.improve(p1, neighbourhood_);
        
        localOptimum = (p1 == p2);
        p1 = p2;
    }
}
\end{lstlisting}
\

The two main classs used in this program are the \emph{Instance} and
\emph{Permutation} classes. The first one loads a matrix from an instance file
and stores it in a 2D vector. The second one contains an array representing the
permutation concept described in the subject's slides.\\

The \textbf{Instance::evaluate()} method is used to compute an instance's score
with the help of a permutation. The following formula corresponds to the sum
computed by this method:\\
$\sum_{i=0}^{n-1} \sum_{j=i+1}^{n-1} m(\pi[i], \pi[j])$, with $\pi$ a permutation.\\

We do not need to recompute the sum from each cells between two permutations,
there are cells which can be reused: $newScore = oldScore - deltaOldScore + deltaNewScore$
with \emph{deltaOldScores} the cells in the old permutation which were modified
in the new permutation and \emph{deltaNewScores} the cells in the new permutation
which were modified in the new permutation. We define the following boolean
variables in order to determine which cells are in common :\\\\

\begin{lstlisting}[caption="Cells in common for transpose \& exchange neighbourhoods"]
bool iInPair = (i == pair.first) || (i == pair.second);
bool jInPair = (j == pair.first) || (j == pair.second);

bool inCommon = (!iInPair && !jInPair)
    || (i == pair.first && !jInPair && j > pair.second)
    || (i == pair.second && !jInPair && j > pair.first)
    || (j == pair.first && !iInPair && i < pair.second)
    || (j == pair.second && !iInPair && i < pair.first);
\end{lstlisting}
\

\begin{lstlisting}[caption="Cells in common for insert neighbourhoods"]
    bool inCommon = (i < first())
        || (i > second())
        || (j < first())
        || (j > second());
\end{lstlisting}
\

\noindent The \emph{inCommon} variable can then be inverted in order to retrieve the
modified cells.\\

\begin{frameurgent}
	In order to know which optimisation to use, I have used an OOP mechanism
	(inclusion polymorphism, \emph{Neighbourhood::inCommon()}) but it slows
	down the program more than if no OOP mechanism was used. The computation
	time is strongly affected by this because the \emph{evaluate()} method is
	the most called method in the program.\\
	
	\noindent In retrospect, it would probably have been more efficient to not use any
	abstraction at all in the program.
\end{frameurgent}

\newpage

\subsection{Results}

As described previously, problems were encountered regarding the computation time
of algorithms with the exchange and insert neighbourhoods. These neighbourhoods
are large and as such take a long time to compute. It would not be feasible to
execute all the rules combination with all the instances, when the exchange
neighbourhood with first improvement and a 150*150 instance takes more than
100 seconds.\\

Optimisations regarding the sum in the evaluation of the score were made
(ignoring the cells which were not modified in the sum), but it was not
sufficient to reduce the computation time. Though, it did improve the
computation time: from 300 seconds to 100 seconds for the case described in the
previous paragraph.\\

One method to reduce the computation time would have been to proceed to
neighbourhood pruning in order to remove some neighbours which would not have
been likely to improved the score.\\

Although the results do not really have any significance, the scripts were run
on simplified neighbourhoods in order to prove that they work as intended. To
reproduce the generation of these results, the \emph{oldNeighbourhoods} branch
can be switched to in \emph{git}.\\

The \emph{script/generate\_experiments.lua} script generates all experiments from
all the rule combinations and instances in a separate file for each rule
combination. The file format and an example can be seen below.\\

\begin{lstlisting}
instance_name score best_known_score relative_percentage_deviation computation_time

N-be75eec_150 2850321 3482828 18.160730303076 1.10763
N-be75eec_250 7456782 8893533 16.155008363943 7.79982
N-be75np_150 5991561 7174325 16.486066633446 0.997437
N-be75np_250 14820463 17814072 16.804742902128 7.66058
...
\end{lstlisting}
\

The \emph{script/compute\_averages.lua} script takes all the data from the
previously generated experiments files and computes averages from it.\\

\begin{lstlisting}
experiment_name average_delta time_sum time_average

ii_cw_best_exchange 17.277346692163 333 4.2692307692308
ii_cw_best_insert 17.084249592579 321 4.1153846153846
ii_cw_best_transpose 17.549047663734 243 3.1153846153846
...
\end{lstlisting}

\begin{framehint}
    All the experiments results were saved in the \emph{experiments} directory.
\end{framehint}

\newpage

\subsection{Tests}
We previously computed the relative percentage deviation for each instance, in
each experiment. We would like to know if there are statistically significant
differences between the solution quality generated by the different algorithms.
In order to do that, we use statistical hypothesis tests, the student's t-test
and the Wilcoxon signed-rank test. This tests test a statement called the
null hypothesis which in this case is: "the median of the differences between
results in two experiments is zero". We fix the significance level $\alpha$ to
0.05. If the computed p-value is below $\alpha$, the null hypothesis is rejected
which in this case means that there is a significant difference between
experiments.\\

An R script (\emph{scripts/statistical\_hypothesis\_tests.R}) was written in order
to apply these tests to all possible pairs of experiments. The output was saved
in the \emph{experiments/stats\_tests} directory (reminder: these
results do not have much significance, because the experiments were run on
the transpose neigbourhoods + 2 other neighbourhoods which were intended by the
assignment subject).\\

\begin{lstlisting}[language=R]
#!/usr/bin/Rscript

# arg[1] should be "ii" or "vnd"
args <- commandArgs(trailingOnly = TRUE)

if (args[1] != "ii" && args[1] != "vnd") {
    stop("Usage: ./script <ii|vnd>")
}

experiments_dir <- "../experiments/"
experiments <- list.files(experiments_dir, args[1])
deltas <- array(0, c(length(experiments), 78))

for (i in 1:length(experiments)) {
    experiment_path <- paste(experiments_dir, experiments[i], sep="")
    deltas[i,] <- read.table(experiment_path)$V4
}

results <- array(0, c(length(experiments), length(experiments), 2))
for (i in 1 : (length(experiments)-1)) {
    for (j in (i+1) : length(experiments)) {
        # Student's t test
        results[i,j,1] <- t.test(deltas[i,], deltas[j,], paired=T)$p.value
        
        # Wilcoxon signed-rank test
        results[i,j,2] <- wilcox.test(deltas[i,], deltas[j,], paired=T)$p.value
    }
}

out.dir = "../out/stats_tests"
out.path = paste(out.dir, args[1], sep="/")
dir.create(out.dir, showWarnings=FALSE)
write.table(results[,,1], paste(out.path, "t", sep="_"))
write.table(results[,,2], paste(out.path, "wilcoxon", sep="_"))
\end{lstlisting}

\newpage
